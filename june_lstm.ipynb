{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "june_lstm.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-3J9eZjFi7n"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import openpyxl\n",
        "import tensorflow as tf\n",
        "from openpyxl import load_workbook\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from pandas import DataFrame\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from pandas import concat\n",
        "from tensorflow.keras.layers import LSTM,Dense,GRU,Dropout,SimpleRNN\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HguzcX5sFvNw"
      },
      "source": [
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    df = DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(i))\n",
        "        names += [('var%d(t-%d)' % (j + 1, i)) for j in range(n_vars)]\n",
        "    # forecast sequence (t, t+1, ... t+n)\n",
        "    for i in range(0, n_out):\n",
        "        cols.append(df.shift(-i))\n",
        "        if i == 0:\n",
        "            names += [('var%d(t)' % (j + 1)) for j in range(n_vars)]\n",
        "        else:\n",
        "            names += [('var%d(t+%d)' % (j + 1, i)) for j in range(n_vars)]\n",
        "    # put it all together\n",
        "    agg = concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "        agg.dropna(inplace=True)\n",
        "    return agg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdR4KfojFzaH"
      },
      "source": [
        "n_hours = 5\n",
        "n_features = 43\n",
        "train_num_24 = 2789\n",
        "train_num_25 = 2892\n",
        "train_num_19 = 1934"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5zTTaMrF5eG"
      },
      "source": [
        "from google.colab import drive\n",
        "filename = '/content/bigcon_data.xlsx'\n",
        "\n",
        "df = pd.read_excel(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeC_Na7pGFWS"
      },
      "source": [
        "# df_metrix 만드는 과정\n",
        "df_matrix = df.to_numpy()\n",
        "df_matrix = df_matrix[1:train_num_25, 5:]\n",
        "print(df_matrix)\n",
        "\n",
        "df_matrix = df_matrix.astype('float32')\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df_matrix = scaler.fit_transform(df_matrix)\n",
        "\n",
        "df_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIXZ9__XGOrQ"
      },
      "source": [
        "# print(df_matrix)\n",
        "lag = series_to_supervised(df_matrix, n_hours,1)\n",
        "\n",
        "# print(lag)\n",
        "# print(lag.shape[1])\n",
        "# for i in range(215,258):\n",
        "#     lag.drop(lag.columns[[i]], axis = 1, inplace = True)\n",
        "\n",
        "\n",
        "lag = lag.values\n",
        "\n",
        "tmp = lag.shape[1]-42\n",
        "\n",
        "lag = lag[:,0:tmp]\n",
        "print(lag.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NFZMZgeGUQO"
      },
      "source": [
        "n_train_hours = train_num_19\n",
        "train = lag[:n_train_hours, :]\n",
        "test = lag[n_train_hours:, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilggz1NPGU8W"
      },
      "source": [
        "n_obs = n_hours * n_features\n",
        "train_X, train_y = train[:, :n_obs], train[:, -n_features]\n",
        "test_X, test_y = test[:, :n_obs], test[:, -n_features]\n",
        "print(train_X.shape, len(train_X), train_y.shape)\n",
        "# reshape input to be 3D [samples, timesteps, features]\n",
        "train_X = train_X.reshape((train_X.shape[0], n_hours, n_features))\n",
        "test_X = test_X.reshape((test_X.shape[0], n_hours, n_features))\n",
        "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W99LSWFGlov"
      },
      "source": [
        "plt.figure(figsize=(20, 10))\n",
        "# sns.lineplot(y=df_scaled['유입량'], x=df['일자'])\n",
        "# plt.xlabel('TIME')\n",
        "# plt.ylabel('AMOUNT')\n",
        "plt.plot(df['유입량'])\n",
        "plt.xlabel('TIME')\n",
        "plt.ylabel('AMOUNT')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4SMUPltHBjn"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(50, input_shape=(train_X.shape[1],train_X.shape[2]), activation='tanh', return_sequences=False))\n",
        "model.add(Dense(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtPtb8fhHfXP"
      },
      "source": [
        "import os\n",
        "from keras import optimizers\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(lr=0.01)\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
        "model_path = 'model'\n",
        "filename = os.path.join(model_path, 'tmp_checkpoint.h5')\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "\n",
        "history = model.fit(train_X, train_y, \n",
        "                                    epochs=100, \n",
        "                                    batch_size=32,\n",
        "                                    validation_data=(test_X, test_y), \n",
        "                                    callbacks=[early_stop, checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH5kOAFCHvFW"
      },
      "source": [
        "model.load_weights(filename)\n",
        "pred = model.predict(test_X)\n",
        "\n",
        "pred.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj2YDP_fH2R1"
      },
      "source": [
        "RMSE = mean_squared_error(test_y,pred)**0.5\n",
        "RMSE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czJHxnvqH-6G"
      },
      "source": [
        "plt.figure(figsize=(12, 9))\n",
        "plt.plot(test_y, label = 'actual')\n",
        "plt.plot(pred, label = 'prediction')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}